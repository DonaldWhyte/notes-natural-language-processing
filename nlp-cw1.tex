%
% Name: Natural Language Processing Coursework 1
% Author: Donald Whyte (sc10dw@leeds.ac.uk)
%

\documentclass{article}

% Make subsections use alphabet indices and not numeric indices
\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\usepackage[margin=3cm]{geometry} % easy page formatting
	
\usepackage{datetime} % up-to-date, automatically generated times
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}

\title{Natural Language Processing \\ COMP3310 \\ Coursework One}
\author{Donald Whyte (sc10dw@leeds.ac.uk)}
\date{\today}

\begin{document}
\lstset{language=Python}
\lstset{basicstyle=\ttfamily}

\maketitle

\section{Most Informative Features for Movie Review Classification}

In order to determine whether or not a movie review is positive or negative, a Naive Bayes classifier can be used. Using NLTK, I trained a \textbf{binomial} Naive Bayes classifier like so:

%
%TODO: isolate splitting code into single function in cw1_base and use in all code
%
%TODO: mention explicitly that I'm using the code form the book (e.g. NOTE) , before she sent out the email about the other code. Still splitting by 3/4 AND NOT RANDOMISING THOUGH!

\begin{lstlisting}
# List of words to use as features for binomial classification
# This will be the 2000 most frequent tokens in the movie_reviews corpus
WORDS_TO_CONSIDER = [ ... ]

def docFeatureExtractor(text):
	text = set(text) # convert to set for faster look-up
	featureSet = {}
	for i in range(len(WORDS_TO_CONSIDER)):
		key = self.featureNames[i]
		featureSet[key] = (WORDS_TO_CONSIDER[i] in text)
	return featureSet

# Build labelled training dataset from movie_reviews corpus
trainingSet = [ ( list(movie_reviews.words(fileid)), category)
			  for category in movie_reviews.categories()
			  for fileid in movie_reviews.fileids(category) ] 
# Use feature extractor on every review
featureSet = apply_features(docFeatureExtractor, trainingSet)
# Train classifier 
classifier = nltk.NaiveBayesClassifier.train(featureSet)
\end{lstlisting}

From this, it is possible to derive which features were the most useful in distinguishing positive or negative movie reviews using the following Python command:

\begin{lstlisting}
	classifier.show_most_informative_features(30)
\end{lstlisting}
Table \ref{tab:informative_features_doc_classification} shows the 30 most informative features for classifying movie reviews as positive or negative, outputted from the above command.

\begin{table}
\centering
\begin{tabular}{|l|l|l|}
	\hline
	\textbf{Rank} & \textbf{Feature} & \textbf{Ratio} \\
	\hline
	1 & contains(outstanding) & positive:negative = 11.5:1.0 \\
	2 & contains(mulan) & positive:negative = 9.0:1.0 \\
	3 & contains(seagal) & negative:positive = 8.2:1.0 \\
	4 & contains(wonderfully) & positive:negative = 7.0:1.0 \\
	5 & contains(damon) & positive:negative = 6.3:1.0 \\
	6 & contains(flynt) & positive:negative = 5.7:1.0 \\
	7 & contains(wasted) & negative:positive = 5.5:1.0 \\
	8 & contains(lame) & negative:positive = 5.5:1.0 \\
	9 & contains(awful) & negative:positive = 5.3:1.0 \\
	10 & contains(poorly) & negative:positive = 5.1:1.0 \\
	11 & contains(ridiculous) & negative:positive = 5.0:1.0 \\
	12 & contains(waste) & negative:positive = 5.0:1.0 \\
	13 & contains(era) & positive:negative = 4.7:1.0 \\
	14 & contains(worst) & negative:positive = 4.4:1.0 \\
	15 & contains(bland) & negative:positive = 4.2:1.0 \\
	16 & contains(unfunny) & negative:positive = 4.2:1.0 \\
	17 & contains(allows) & positive:negative = 4.1:1.0 \\
	18 & contains(jedi) & positive:negative = 4.1:1.0 \\
	19 & contains(stupid) & negative:positive = 3.9:1.0 \\
	20 & contains(dull) & negative:positive = 3.9:1.0 \\
	21 & contains(fantastic) & positive:negative = 3.9:1.0 \\
	22 & contains(laughable) & negative:positive = 3.9:1.0 \\
	23 & contains(portrayal) & positive:negative = 3.8:1.0 \\
	24 & contains(mess) & negative:positive = 3.8:1.0 \\
	25 & contains(pointless) & negative:positive = 3.8:1.0 \\
	26 & contains(terrific) & positive:negative = 3.8:1.0 \\
	27 & contains(memorable) & positive:negative = 3.7:1.0 \\
	28 & contains(superb) & positive:negative = 3.6:1.0 \\
	29 & contains(boring) & negative:positive = 3.5:1.0 \\
	30 & contains(badly) & negative:positive = 3.5:1.0 \\
	\hline
\end{tabular}
\caption{30 Most Informative Features for Classifying Movie Reviews}
\label{tab:informative_features_doc_classification}
\end{table}

TODO: explain why these features are the most useful and why some are surprising

TODO: surprising ones are actor's names and movie-specific concepts (e.g. jedi). THis is a sign that the classifier has overfit the test data

TODO: strong adjectives which imply positive or negative feelings, so not suprising they correlate to sentiment of movie review

\section {Classification Mistakes}

\subsection{Movie Review 1 (Overfitting Training Data)}

\begin{quote}
"So this is the first time that Steven Seagal has starred in a Sci-Fi movie. I was blown away by "Sheer Space Seagal" and the amazing performances of every actor involved. I highly recommend you watch this movie."
\end{quote}

As table \ref{tab:informative_features_doc_classification} shows, the word 'seagal' tends to appear in negative movie reviews, based on the training data. Assumming 'seagal' is used in the context of Steven Seagal, a known actor in action movies, this appears to mean that the classifier has associated Seagal with bad movies.

Since the negative:positive ratio is quite high for the word 'seagal', when 'seagal' does appear in a review it strongly pushes the review towards being classified as negative. The movie review given below is a very positive review of a movie that Seagal starred in. Despite the overall language being positive, the review has been classified as negative due to the occurrence of 'seagal'.

This implies that the classifier may have \textit{overfit} the training data, identifying distinguishing features specific to the training dataset itself and not movie reviews as whole. This is the reason the classifier has not generalised well and incorrectly classifies this particular review as negative.

TODO: take a lot of evidence to balance out negative seagal

TODO: mention other irrelevant statemnts that have negative statements


\subsection{Movie Review 2 (Discourse, Sentence Subject and Context)}

\begin{quote}
"The original Star Wars trilogy is a masterpiece. It took the world by storm and captivated both children and adults. It was memorable, being talked about for years, and the conclusion to Epsiode VI was outstanding.

It was the end of an era when Episode VI finished. When it was announced that George Lucas would be releasing a prequel trilogy, everyone was excited. What new adventures with the Jedi would happen in the exciting Star Wars universe?

Naturally, there's been a lot of discussion about Episode I. Everyone was queueing up and was buzzing with excitement as they were about to watch the movie.

Like many people however, when I left the movie I felt disappointed. It was nowhere near the same fantastic quality the original trilogy had. In fact, I think it was a poor movie. Remember that when going into this movie."
\end{quote}

The reason the classifier struggles to identify the following text as a negative review of Star Wars Episode I is because it does not take \textit{discourse} into account. Discourse is the relationship between sentences and text at different positions of a document.

Since the bag of words model does not take position into account, the classifier has no way of distinguishing between words about the original Star Wars trilogy from words that are about Episode I specifically. TODO: lead into sentence subject!]

TODO: further examples of limited sentence subject in this as well.

Therefore, when the writer is praising the original trilogy, the classifier just assumes that the writer is praising the movie being reviewed. This results in the classifier thinking it's a positive review, when in actual fact it's a negative review (as shown by the last paragraph).

\section{Impact of Feature Selection Methods}

TODO: feature selection code for EACH TYPE should a function EACH. 

\subsection{Frequency Cutoff}

TODO: what I did (no new code)

TODO: table with different values for k

TODO: results and discussion

\subsection{Association Measure - Mutual Information}

TODO: what I did

TODO: different values of k with table

TODO: results and discussion

\subsection{Function Word Exclusion (Stopwords)}

TODO: what I did

TODO: results didn't change that much, because ratios will be quite balanced anyway. Just noise, so can't guarantee which way it'll go.

TODO: table with frequency/mutual information for both STOPWORDS and NON-STOPWORDS

TODO: results and discussion

From basic tests,

\subsection{Summary}

TODO: compare using all the different approaches and summarise discussion in other subsections

\section{Generalising Words using WordNet}

TODO: generalise words in each document using WordNet lexicon (boil down words to their base meaning)

TODO: add all synonyms sets to document (UNLESS a synonym is BELOW a certain threshold with similarity measure - call it t). Provide a few values of t for results

TODO: replace word with a hypernym (number of levels to go up should be tweakable - say p is max up)

TODO: say what I'm going to generalise (synonyms, hypernynms, some additional creativity) and how I did it in code

TODO: results and discussion

\section{Theory: Bag of Words Representations}

\begin{itemize}
	\item \textbf{D1} -- there are differences between the two BOW representation, because commas and the word "London" appear more than once. \begin{itemize}
		\item \textbf{Bernoulli Model}: ['He', 'moved', 'from', 'London', ',', 'Ontario', 'to', 'England']
		\item \textbf{Multinomial Model}: ['He', 'moved', 'from', 'London', ',', 'Ontario'. ',', 'to', 'London', ',', 'England']
		\end{itemize}
	\item \textbf{D2} -- there are differences between the two BOW representation, because commas and the word "London" appear more than once. \begin{itemize}
		\item \textbf{Bernoulli Model}: ['He', 'moved', 'from', 'London', ',', 'England', 'to', 'Ontario']
		\item \textbf{Multinomial Model}: ['He', 'moved', 'from', 'London', ',', 'England', ',', 'to', 'London', ',', 'Ontario']
	  \end{itemize}
	\item \textbf{D3} -- there are no differences in the BOW representations, as there are no repeated tokens.
	\begin{itemize}
	\item \textbf{Bernoulli Model}: ['He', 'moved', 'from', 'England', 'to', 'London', ',', 'Ontario']
	\item \textbf{Multinomial Model}: ['He', 'moved', 'from', 'England', 'to', 'London', ',', 'Ontario']
	\end{itemize}
\end{itemize}

\section{Theory: Estimating Classifiers}

\begin{table}[h]
	\centering
	\begin{tabular}{|l|l|l|l|}
	\hline
	& \textbf{Document ID} & \textbf{Words in Document} & \textbf{in $c=$China?} \\
	\hline
	Training Set & 1 & Taipei Taiwan & yes \\
	& 2 & Macao Taiwan Shanghai & yes \\
	& 3 & Japan Sapporo & no \\
	& 4 & Sapporo Osaka Taiwan & no \\
	\hline
	Test Set & 5 & Taiwan Taiwan Sapporo & ? \\
	\hline 
	\end{tabular}
	\caption{Training and Test Datasets for Naive Bayes Classifiers}
	\label{tab:example_problem}
\end{table}

\begin{align}
P(China) = \frac{2}{4} \\
P(notChina) = \frac{2}{4} \\
V = \lbrace Taipei, Taiwan, Macao, Shanghai, Japan, Sapporo, Osaka \rbrace \\
|V| = 7
\end{align}

\subsection{Multinomial Naive Bayes Classifier}

\begin{tabular}{l}
\textbf{Large document} for class $China$ is: "Taipei Taiwan Macao Taiwan Shanghai". \\
\textbf{Large document} for class $notChina$ is: "Japan Sapporo Sapporo Osaka Taiwan" \\
$P(w_i|c) = \frac{n_i^c + 1}{n^c + |V|}$
\end{tabular}

\hspace{2pt}

For class $China$:
\begin{align}
n^{China} = 5 \\
P(Taipei|China) = P(Macao|China) = P(Shanghai|China) = \frac{1 + 1}{5 + 7} = \frac{2}{12} \\
P(Taiwan|China) = \frac{2 + 1}{5 + 7} = \frac{3}{12} \\
P(Japan|China) = P(Sapporo|China) = P(Osaka|China) = \frac{0 + 1}{5 + 7} = \frac{1}{12}
\end{align}

For class $notChina$:
\begin{align}
n^{notChina} = 5 \\
P(Japan|notChina) = P(Osaka|notChina) = P(Taiwan|notChina) = \frac{1 + 1}{5 + 7} = \frac{2}{12} \\
P(Sapporo|notChina) = \frac{2 + 1}{5 + 7} = \frac{3}{12} \\
P(Taipai|China) = P(Macao|China) = P(Shanghai|China) = \frac{0 + 1}{5 + 7} = \frac{1}{12} \\
\end{align}

Applying classifier to document 5:
\begin{align}
	P(China|doc5) & \propto P(China) \cdot \prod_{i \in positions} {P(w_i|China)} \\
	& \propto \frac{1}{2} \cdot P(Taiwan|China) \cdot P(Taiwan|China) \cdot P(Sapporo|China) \\
	& \propto \frac{1}{2} \cdot \frac{3}{12}^2 \cdot \frac{1}{12} \\
	& \propto \frac{6}{12} \cdot \frac{3}{12}^2 \cdot \frac{1}{12} \\
	& \propto \frac{54}{20736} \\
	& \propto 0.002604 \\
	& \nonumber \\ 
	P(notChina|doc5) & \propto P(notChina) \cdot \prod_{i \in positions} {P(w_i|China)} \\
	& \propto \frac{1}{2} \cdot P(Taiwan|notChina) \cdot P(Taiwan|notChina) \cdot P(Sapporo|notChina) \\
	& \propto \frac{1}{2} \cdot \frac{2}{12}^2 \cdot \frac{3}{12} \\
	& \propto \frac{6}{12} \cdot \frac{2}{12}^2 \cdot \frac{3}{12} \\	
	& \propto \frac{72}{20736} \\
	& \propto 0.00372
\end{align}

Therefore, a multinomial Naive Bayes classifier would label document 5 with the class $notChina$.

\subsection{Bernoulli Naive Bayes Classifier}

TODO: verify that this equation is correct
$P(e_i|c) = \frac{\#\;documents\;of\;class\;c\;that\;contain\;word w_i + 1}{\#\;documents\;of\;class\;c + 2}$

For class $China$:
\begin{align}
P(Taipei|China) = P(Macao|China) = P(Shanghai|China) = \frac{1 + 1}{2 + 2} = \frac{2}{4} \\
P(Taiwan|China) = \frac{2 + 1}{2 + 2} = \frac{3}{4} \\
P(Japan|China) = P(Sapporo|China) = P(Osaka|China) = \frac{0 + 1}{2 + 4} = \frac{1}{4}
\end{align}

For class $notChina$:
\begin{align}
P(Japan|China) = P(Osaka|China) = P(Taiwan|China) = \frac{1 + 1}{2 + 2} = \frac{2}{4} \\
P(Sapporo|China) = \frac{2 + 1}{2 + 2} = \frac{3}{4} \\
P(Taipei|China) = P(Macao|China) = P(Shanghai|China) = \frac{0 + 1}{2 + 4} = \frac{1}{4}
\end{align}

Applying classifier to document 5:
\begin{align}
	P(China|doc5) & \propto P(China) \cdot \prod_{w_i \in V} {Pe_i|China)} \\
	& \propto \frac{1}{2} \cdot P(Taiwan|China) \cdot P(Sapporo|China) \nonumber \\
	& \cdot (1 - P(Taipei|China)) \cdot (1 - P(Macao|China)) \cdot (1 - P(Shanghai|China)) \nonumber \\
	& \cdot (1 - P(Japan|China)) \cdot (1 - P(Osaka|China)) \\
	& \propto \frac{1}{2} \cdot \frac{3}{4} \cdot \frac{1}{4}
	\cdot \frac{2}{4} \cdot \frac{2}{4} \cdot \frac{2}{4}
	\cdot \frac{3}{4} \cdot \frac{3}{4} \\
	& \propto \frac{2}{4} \cdot \frac{3}{4} \cdot \frac{1}{4}
	\cdot \frac{2}{4} \cdot \frac{2}{4} \cdot \frac{2}{4}
	\cdot \frac{3}{4} \cdot \frac{3}{4} \\
	& \propto \frac{432}{65536} \\
	& \propto 0.006591 \\
	& \nonumber \\
	P(notChina|doc5) & \propto P(notChina) \cdot \prod_{w_i \in V} {Pe_i|China)} \\
	& \propto \frac{1}{2} \cdot P(Taiwan|notChina) \cdot P(Sapporo|notChina) \nonumber \\
	& \cdot (1 - P(Taipei|notChina)) \cdot (1 - P(Macao|notChina)) \nonumber \\
	& \cdot (1 - P(Shanghai|notChina)) \cdot (1 - P(Japan|notChina)) \nonumber \\
	& \cdot (1 - P(Osaka|notChina)) \\	
	& \propto \frac{1}{2} \cdot \frac{2}{4} \cdot \frac{3}{4} \cdot \frac{3}{4} \cdot \frac{3}{4} \cdot \frac{3}{4} \cdot \frac{2}{4} \cdot \frac{2}{4} \\
	& \propto \frac{2}{4} \cdot \frac{2}{4} \cdot \frac{3}{4} \cdot \frac{3}{4} \cdot \frac{3}{4} \cdot \frac{3}{4} \cdot \frac{2}{4} \cdot \frac{2}{4} \\
	& \propto \frac{1296}{64436} \\
	& \propto0.01977
\end{align}

Therefore, a Bernoulli, binomial Naive Bayes classifier would label document 5 with the class $notChina$.

\end{document}