## Natural Language Processing Coursework 1 (Text Classification)

This coursework was about using text classifiers to classify movie reviews
as either positive or negative. Read the document generated from `nlp-cw1.text`
for more information. The document is generated by running `make` in this
directory.

The rest of this README explains how to run the associated Python scripts.

### Running Naive Bayes Classifier to Detect Reviews

To run the binomial Naive Bayes classifier, using frequency cutoff with 2000
words for feature selection, run the following script:

```
python cw1_base.py
```

### Most Information Features

To find out the 30 most informative features for classifying movie review
sentiment (from frequency cutoff with 200 features), run:

```
python q1.py
```

### See Incorrectly Classified Movie Reviews

To see the two movie reviews described in section 2 of the report incorrectly
classified, run:

```
python q2.py
```

### How `k` Affects Frequency Cutoff

To test the impact on accuracy different values of `k` have with **frequency
cutoff**, then you can run the following script:

```
python q3a.py <numFeaturesToUse> <filterStopWords>
```

where `<numFeaturesToUse>` is a positive integer which determines the number
of features used for classification (value of k) and `<filterStopWords>` is
a flag that decides if function words are exluded form the corpus. If
`<filterStopWords>` is `true`, then function words will be excluded. Otherwise,
they will be included in feature selection, extraction and classification.

### How `k` Affects Mutual Information

To test the impact on accuracy different values of `k` have with **mutual
information**, then you can run the following script:

```
python q3b.py <numFeaturesTouse> <filterStopWords> \
              {<mutualInformationCacheFilename>}
```

for `<numFeaturesTouse>` and `<filterStopWords>` mean the same things as they
do in `q3a.py`. `<mutualInformationCacheFilename>` is a optional argument. If
used, then the script won't compute each word's mutual information. Instead, it
will use the pre-computed values for the words present in the specified file.
This is useful for running the script multiple times, as mutual information
is not recomputed every time.

`<mutualInformationCacheFilename>` should point to a binary file which a 
**pickled Python dictionary**. This file can be prododued by running the 
Python script `mutual_information.py`.

### Generate Mutal Information of Words

To generate a file which contains mutual information values for all words in
the `movie_reviews` corpus, run the following script:

```
python mutual_information.py <outputFilename>
```

where `<outputFilename>` is the desired name of the file to be generated.

### Classification Accuracy with Additional Features

To test the accuracy of classifiers which use some of the additional features
described in section 4 of the report (WordNet features), the following script
can be used:

```
python q4.py <featureSetToUse> <numFeaturesToUse>
```

where `<numFeaturesToUse>` is the value of k to use for frequency cutoff
feature selection and `<featureSetToUse>` determines which WordNet-related
features to use.

Possible feature sets:

* `word` -- exact word occurrences considered (contains(x) features used in previous questions)
* `syn` -- synonyms of words considered
* `hyp` -- hypernyms of words considered
* `word-adj` -- get all adjective synonyms of words. If one of those adjectives is the same as a word feature, consider the feature word as being present the document (MUST BE USED WITH `word` feature set).

These can be combined using `-`. For example, to consider words, synoynms
and hypernyms, use `word-syn-hyp`.
